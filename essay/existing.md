kafka, flink, spark, samza, 

# start

there are [numerous](https://en.wikipedia.org/wiki/Stream_processing#Stream_programming_libraries_and_languages) streaming data processing engines, frameworks, etc.

Lets start with one topic and see where it gets us.

## This starting point will be [apache beam](https://beam.apache.org/)
One eficient strategy is separation of concerns. in a state, someone 
makes the laws, the legislative branch, and someone else ensures 
that those laws are followed. 

This is what Beam helps in terms of data processing. The data 
processing pipelines are defined using beam, and then another system 
[chooses](https://medium.com/swlh/dataflow-and-apache-beam-the-result-of-a-learning-process-since-mapreduce-c591b2ab180e) 
how to run the pipeline. 

Some of those systems are:
 - Google Cloud Dataflow
 - Apache Flink
 - Apache Spark
 - Apache Samza

 
 The first concept in streaming data processing is the[ _window and windowing functions_ ](https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines#windows)

 Windows group data bites by their timestamp.
 Beam has 3 types of windows:
 - Fixed
 - Sliding
 - Session

 ### Fixed windows

 A fixed window represents a consistent, disjoint time interval in the data stream.

For example, if you set to a thirty-second fixed window, the 
elements with timestamp values [0:00:00-0:00:30) are in the first 
window. Elements with timestamp values [0:00:30-0:01:00) are in the 
second window.

![reprezentation of fixed window](https://cloud.google.com/dataflow/images/fixed-time-windows.png)

### Sliding windows

A sliding window represents a consistent time interval in the data 
stream. Sliding windows can overlap, whereas tumbling windows are 
disjoint.

For example, a sliding window can start every ten seconds and 
capture one minute of data and the window. The frequency with which 
sliding windows begin is called the period. This example has a 
one-minute window and thirty-second period.

The following image illustrates how elements are divided into 
one-minute sliding windows with a thirty-second period.

![reprezentation of sliding window](https://cloud.google.com/dataflow/images/sliding-time-windows.png)

### Session windows

A session window contains elements within a gap duration of another 
element. The gap duration is an interval between new data in a data 
stream. If data arrives after the gap duration, the data is assigned 
to a new window.

For example, session windows can divide a data stream representing 
user mouse activity. This data stream might have long periods of 
idle time interspersed with many clicks. A session window can 
contain the data generated by the clicks.

![reprezentation of session window](https://cloud.google.com/dataflow/images/session-windows.png)

### Watermarks

[In a distributed system with inputs from all over the world, data arrival time does not strictly correspond to its generation time](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/41378.pdf)

Data comes with a delay. This delay is taken into consideration with 
a watermark. a watermark signifies the diference between the data 
fragment timestamp and the time of arrival at our system.

### Triggers

Triggers determine when to emit aggregated results as data arrives. 
By default, results are emitted when the watermark passes the end of 
the window.

You can use the Apache Beam SDK to create or modify triggers for 
each collection in a streaming pipeline.

The Apache Beam SDK can set triggers that operate on any combination 
of the following conditions:

 - Event time, as indicated by the timestamp on each data element.
 - Processing time, which is the time that the data element is processed at any given stage in the pipeline.
 - The number of data elements in a collection.
